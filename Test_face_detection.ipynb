{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohdRasmil7/ML-notebooks/blob/main/Test_face_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edit to fill this\n",
        "\n",
        "__Name__: Muhammed Rasmil CH\n",
        "\n",
        "__Email id__: muhammedrasmil2001@gmail.com\n",
        "\n",
        "\n",
        "To start go to file tab and create a copy of this notebook on your own drive"
      ],
      "metadata": {
        "id": "d4znkzC1tYBT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Objective:__ Given the input video file localize and draw bounding boxes around the face of characters."
      ],
      "metadata": {
        "id": "PbsSmDeEiMCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Candidate can use any methohd or platform to tackle this problem. not a fan of colab downlaod the video on to your system using [video](https://drive.google.com/file/d/1nyeeqBJyDr2zphBDQ9ruh99JBdYm4nPH/view?usp=sharing) and upload the solution back here with your code attached.\n",
        "\n",
        "- You are free to use any model or module, either trained by you or state-of-the-art.\n",
        "- The code should be well-documented. One can also use markdown cells to write your approach for every step.\n",
        "- In case of plagiarism, the candidate will be immediately rejected. You can use some helper code available online but must be appropriately referenced."
      ],
      "metadata": {
        "id": "z2UH-uNarZIS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RbXUY_Y2XLYu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d5230a7-fee9-4ed9-8dd7-9f0843bda653"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nyeeqBJyDr2zphBDQ9ruh99JBdYm4nPH\n",
            "To: /content/test_video.mp4\n",
            "\r  0% 0.00/7.54M [00:00<?, ?B/s]\r 76% 5.77M/7.54M [00:00<00:00, 52.9MB/s]\r100% 7.54M/7.54M [00:00<00:00, 56.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "# run this to download the video file as test_video.mp4\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1nyeeqBJyDr2zphBDQ9ruh99JBdYm4nPH/view?usp=sharing --output test_video.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Your approach here"
      ],
      "metadata": {
        "id": "wVG6sk6YtQvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import cv2\n",
        "import dlib\n"
      ],
      "metadata": {
        "id": "SJ4GL0V4qWwn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_video = \"/content/test_video.mp4\""
      ],
      "metadata": {
        "id": "JCbM3TzV1rL6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize dlib's face detector (using HOG + SVM-based detection)\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "# Open the video file using OpenCV's VideoCapture\n",
        "cap = cv2.VideoCapture(path_video)\n",
        "\n",
        "# Check if the video opened successfully\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Could not open video.\")\n",
        "    exit()\n",
        "\n",
        "# Get video properties like width, height, and frames per second (FPS)\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Set the codec for output video (mp4 format)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "\n",
        "# Create a VideoWriter object to save the processed video with bounding boxes\n",
        "out = cv2.VideoWriter('result_video.mp4', fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Loop through each frame in the video\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()  # Read the next frame\n",
        "    if not ret:  # If no more frames are available, exit the loop\n",
        "        break\n",
        "\n",
        "    # Convert frame to grayscale for better performance with face detection\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces in the frame using dlib\n",
        "    faces = detector(gray)\n",
        "\n",
        "    # Draw bounding boxes around detected faces\n",
        "    for face in faces:\n",
        "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
        "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Draw green boxes for detected faces\n",
        "\n",
        "    # Write the processed frame (with bounding boxes) to the output video\n",
        "    out.write(frame)\n",
        "\n",
        "# Release the video capture and writer objects to save the output\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(\"Processing complete! The result video has been saved as 'result_video.mp4'.\")"
      ],
      "metadata": {
        "id": "GCpcvISrwmf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec08b479-26a1-4c2f-e343-5d2835372a0e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complete! The result video has been saved as 'result_video.mp4'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('result_video.mp4')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "sBbX6EmvGfMV",
        "outputId": "21d4d3c2-4177-4f37-caf1-29bd9e34c483"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_92ce81eb-7da8-42dc-a343-5cc65228d079\", \"result_video.mp4\", 16955021)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# result video\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "!cp result_video.mp4 /content/drive/MyDrive/1Ui5w_MbDYEbJ82SBF_SsAwl54h_5tJm0/\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCeKXEdOGkAN",
        "outputId": "7b4f45db-1baf-41a4-e4ac-c7c9b38e3879"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "cp: cannot create regular file '/content/drive/MyDrive/1Ui5w_MbDYEbJ82SBF_SsAwl54h_5tJm0/': Not a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions"
      ],
      "metadata": {
        "id": "sQPlLUKHt9Xp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### __Q1:__ What is the video processing library and localization model you used?\n",
        "\n",
        "__ANS__ :  I used OpenCV for video processing, handling the video input/output, and dlib's HOG + SVM-based face detector for face localization.\n"
      ],
      "metadata": {
        "id": "KcsERn4ouB-q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### __Q2:__ If given enough resources, time or data. what better approach you might have implemented?\n",
        "\n",
        "__ANS__ : With more resources, I would have used deep learning-based models like MTCNN or RetinaFace, which are more accurate and efficient for detecting faces under challenging conditions like occlusion or low light."
      ],
      "metadata": {
        "id": "8rCI5cH1urMp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### __Q3:__ Explain some real life use cases of Object detection or localization. If you have a project using these also explain that problem statement.\n",
        "__ANS__ : Object detection is used in surveillance, autonomous vehicles, and even healthcare for tracking and identifying objects. I worked on a project that involved detecting specific fields in legal documents to automate the extraction of important data."
      ],
      "metadata": {
        "id": "bLVbwOMXuvZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### __Q4:__ Explain breifly model architectue of ResNet?\n",
        "__ANS__ : ResNet (Residual Network) uses skip connections to pass information across layers, solving the vanishing gradient problem. This architecture allows training very deep networks efficiently, as it helps the model focus on learning residual functions rather than mapping all input directly to output."
      ],
      "metadata": {
        "id": "NYbMatzLwRKS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iOmYv0mkL1_3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}